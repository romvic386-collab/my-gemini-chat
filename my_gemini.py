import streamlit as st
import google.generativeai as genai

# --- –í–°–¢–ê–í–¨ –°–í–û–ô –ö–õ–Æ–ß –°–Æ–î–ê ---
API_KEY = st.secrets["GOOGLE_API_KEY"]

genai.configure(api_key=API_KEY)

# --- –ù–ê–°–¢–†–û–ô–ö–ò –°–¢–†–ê–ù–ò–¶–´ ---
st.set_page_config(page_title="My Gemini Hub", page_icon="üéõÔ∏è")

# --- –ë–û–ö–û–í–ê–Ø –ü–ê–ù–ï–õ–¨ (–í–´–ë–û–† –ú–û–î–ï–õ–ò) ---
with st.sidebar:
    st.title("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    # –°–æ–∑–¥–∞–µ–º –≤—ã–ø–∞–¥–∞—é—â–∏–π —Å–ø–∏—Å–æ–∫
    selected_model = st.radio(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
        options=["gemini-2.5-pro", "gemini-2.5-flash"], # –¢–≤–æ–∏ –º–æ–¥–µ–ª–∏ –∏–∑ —Å–∫—Ä–∏–Ω–æ–≤
        captions=["–£–º–Ω–∞—è –∏ –º–æ—â–Ω–∞—è (Reasoning)", "–ë—ã—Å—Ç—Ä–∞—è –∏ –ª–µ–≥–∫–∞—è"], # –ü–æ–¥–ø–∏—Å–∏
        index=0 # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—ã–±—Ä–∞–Ω–∞ –ø–µ—Ä–≤–∞—è
    )
    
    st.divider()
    st.info(f"–ê–∫—Ç–∏–≤–Ω–∞: **{selected_model}**")
    
    # –ö–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —á–∞—Ç–∞ (–¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞)
    if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é"):
        st.session_state.messages = []
        st.rerun()

# --- –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° ---
st.title(f"üí¨ –ß–∞—Ç —Å {selected_model}")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏
if "messages" not in st.session_state:
    st.session_state.messages = []

# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–µ–ø–∏—Å–∫—É
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# –ü–æ–ª–µ –≤–≤–æ–¥–∞
if prompt := st.chat_input("–ù–∞–ø–∏—à–∏ –∑–∞–ø—Ä–æ—Å..."):
    # 1. –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤–æ–ø—Ä–æ—Å —é–∑–µ—Ä–∞
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 2. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
    try:
        # –¢—É—Ç –º—ã –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é selected_model, –∫–æ—Ç–æ—Ä—É—é –≤—ã–±—Ä–∞–ª–∏ –≤ –º–µ–Ω—é
        model = genai.GenerativeModel(selected_model)
        
        with st.chat_message("assistant"):
            # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∞ "–ø–µ—á–∞—Ç–∞–Ω–∏—è" (—Å—Ç—Ä–∏–º–∏–Ω–≥)
            message_placeholder = st.empty()
            full_response = ""
            
            # –í–∫–ª—é—á–∞–µ–º –ø–æ—Ç–æ–∫–æ–≤—É—é –ø–µ—Ä–µ–¥–∞—á—É (—á—Ç–æ–±—ã —Ç–µ–∫—Å—Ç –ø–æ—è–≤–ª—è–ª—Å—è –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ)
            response = model.generate_content(prompt, stream=True)
            
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "‚ñå")
            
            message_placeholder.markdown(full_response)
            
        st.session_state.messages.append({"role": "assistant", "content": full_response})
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ API ({selected_model}): {e}")
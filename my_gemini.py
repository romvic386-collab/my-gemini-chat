import streamlit as st
import google.generativeai as genai
import time

# --- –ù–ê–°–¢–†–û–ô–ö–ò –°–¢–†–ê–ù–ò–¶–´ ---
st.set_page_config(page_title="Gemini Hub", page_icon="üõ°Ô∏è", layout="centered")

# --- –ì–õ–û–ë–ê–õ–¨–ù–ê–Ø –ü–ê–ú–Ø–¢–¨ (–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–∏ F5) ---
@st.cache_resource
def get_global_history():
    return [] # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–µ—Ä–≤–µ—Ä–∞

# –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø –∫ "–≤–µ—á–Ω–æ–º—É" —Å–ø–∏—Å–∫—É
global_history = get_global_history()

# --- –ë–û–ö–û–í–ê–Ø –ü–ê–ù–ï–õ–¨ ---
with st.sidebar:
    st.header("üéõÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    # 1. –í–´–ë–û–† –ö–õ–Æ–ß–ê
    available_keys = [k for k in st.secrets.keys() if k.startswith("KEY_")]
    if available_keys:
        selected_key_name = st.selectbox(
            "üîë –í—ã–±–µ—Ä–∏ –∫–ª—é—á API:",
            options=available_keys,
            format_func=lambda x: f"–ö–ª—é—á #{x.split('_')[1]}"
        )
        API_KEY = st.secrets[selected_key_name]
    else:
        st.error("–î–æ–±–∞–≤—å –∫–ª—é—á–∏ (KEY_1, KEY_2...) –≤ Secrets!")
        st.stop()

    st.divider()

    # 2. –í–´–ë–û–† –ú–û–î–ï–õ–ò
    selected_model = st.radio(
        "üß† –ú–æ–¥–µ–ª—å:",
        options=["gemini-2.5-pro", "gemini-2.5-flash", "gemini-3-pro-preview"], 
        index=1
    )
    
    st.divider()
    
    # 3. –£–ü–†–ê–í–õ–ï–ù–ò–ï –ò–°–¢–û–†–ò–ï–ô
    if st.button("üóëÔ∏è –°—Ç–µ—Ä–µ—Ç—å –∏—Å—Ç–æ—Ä–∏—é (–£ –≤—Å–µ—Ö)"):
        global_history.clear() # –û—á–∏—â–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫
        st.rerun()

    # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ
    chat_history_text = ""
    for msg in global_history:
        chat_history_text += f"{msg['role'].upper()}: {msg['content']}\n\n"
            
    st.download_button(
        label="üíæ –°–∫–∞—á–∞—Ç—å –¥–∏–∞–ª–æ–≥ (.txt)",
        data=chat_history_text,
        file_name="gemini_history.txt",
        mime="text/plain"
    )

# --- –ù–ê–°–¢–†–û–ô–ö–ê API ---
genai.configure(api_key=API_KEY)

# --- –û–°–ù–û–í–ù–û–ô –ß–ê–¢ ---
st.title(f"üí¨ –ß–∞—Ç ({selected_model})")

# –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º —Å–µ—Å—Å–∏—é –∫ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏
# –¢–µ–ø–µ—Ä—å st.session_state.messages ‚Äî —ç—Ç–æ —Å—Å—ã–ª–∫–∞ –Ω–∞ global_history
if "messages" not in st.session_state:
    st.session_state.messages = global_history

# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è (–±–µ—Ä–µ–º –∏—Ö –∏–∑ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –ø–∞–º—è—Ç–∏)
for message in global_history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# –ü–æ–ª–µ –≤–≤–æ–¥–∞
if prompt := st.chat_input("–ù–∞–ø–∏—à–∏ –∑–∞–ø—Ä–æ—Å..."):
    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –ì–õ–û–ë–ê–õ–¨–ù–´–ô —Å–ø–∏—Å–æ–∫
    global_history.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        try:
            model = genai.GenerativeModel(selected_model)
            response = model.generate_content(prompt, stream=True)
            
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "‚ñå")
                    time.sleep(0.01)
            
            message_placeholder.markdown(full_response)
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç —Ç–æ–∂–µ –≤ –ì–õ–û–ë–ê–õ–¨–ù–´–ô —Å–ø–∏—Å–æ–∫
            global_history.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞: {e}")
